{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                        # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt           # 2D plotting library producing publication quality figures\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "print(\"Environment Ready\")\n",
    "\n",
    "# Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "# cfg.enable_device_from_file(\"stairs.bag\")\n",
    "width : int= 640\n",
    "height : int= 480\n",
    "cfg.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "profile = pipe.start(cfg);print(\"pipline start\")\n",
    "\n",
    "# Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "for x in range(5):\n",
    "    pipe.wait_for_frames()\n",
    "\n",
    "#get device information\n",
    "depth_sensor = profile.get_device().first_depth_sensor(); #print(\"depth sensor:\",depth_sensor)\n",
    "depth_scale = depth_sensor.get_depth_scale(); #print(\"depth scale:\",depth_scale)\n",
    "clipping_distance_in_meters = 1.0 # meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "print(\"clipping_distance:\",clipping_distance)\n",
    "\n",
    "# Alignオブジェクト生成\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# set frame Number\n",
    "frameNo = 0\n",
    "\n",
    "# Store next frameset for later processing:\n",
    "frameset = pipe.wait_for_frames()\n",
    "frameNo = frameset.get_frame_number()\n",
    "aligned_frames = align.process(frameset)\n",
    "color_frame = aligned_frames.get_color_frame()\n",
    "depth_frame = aligned_frames.get_depth_frame()  #depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# Cleanup:\n",
    "# pipe.stop()\n",
    "print(\"Color and depth Frames Captured\")\n",
    "\n",
    "# get frames for average filter  original\n",
    "# profile = pipe.start(cfg)\n",
    "\n",
    "frames = []\n",
    "frameNos = []\n",
    "hole_filling = rs.hole_filling_filter()\n",
    "\n",
    "for x in range(10):\n",
    "    frameset = pipe.wait_for_frames()\n",
    "    aligned_frameset = align.process(frameset)\n",
    "    frameNos.append(frameset.get_frame_number())\n",
    "    tmp_depth_frame = aligned_frames.get_depth_frame()\n",
    "    frames.append(hole_filling.process(tmp_depth_frame))\n",
    "\n",
    "pipe.stop();print(\"pipeline stopped\")\n",
    "print(\"Frames for average filter are Captured\")\n",
    "\n",
    "print(\"frameNo: \",frameNo)\n",
    "print(\"frameNos: \",frameNos)\n",
    "\n",
    "\n",
    "\n",
    "#visualising the Data\n",
    "colorizer = rs.colorizer()\n",
    "colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.imshow(colorized_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
